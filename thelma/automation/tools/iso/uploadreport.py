"""
Tools performing tasks around the actual ISO generation (upload
of results, warnings and ISO request files to the trac).

AAB
"""

from thelma.automation.tools.iso.prep_utils import IsoControlRackLayout
from thelma.automation.tools.iso.prep_utils import PrepIsoLayout
from thelma.automation.tools.iso.stocktransfer import StockTransferExecutor
from thelma.automation.tools.semiconstants import EXPERIMENT_SCENARIOS
from thelma.automation.tools.semiconstants import RACK_SHAPE_NAMES
from thelma.automation.tools.utils.base import VOLUME_CONVERSION_FACTOR
from thelma.automation.tools.utils.base import WorkingLayout
from thelma.automation.tools.utils.base import get_trimmed_string
from thelma.automation.tools.writers import CsvColumnParameters
from thelma.automation.tools.writers import CsvWriter
from thelma.automation.tracbase import BaseTracTool
from thelma.models.container import Tube
from thelma.models.job import IsoJob
from thelma.models.liquidtransfer import ExecutedWorklist
from tractor import AttachmentWrapper
from tractor import create_wrapper_for_ticket_update
from xmlrpclib import Fault
from xmlrpclib import ProtocolError
import logging

__docformat__ = 'reStructuredText en'

__all__ = ['StockTransferReportUploader',
           'StockTransferLogFileWriter']


class StockTransferReportUploader(BaseTracTool):
    """
    After each stock transfer the ticket of the referring ISO request
    is updated. This tools add a log file containing information about
    the transferred samples and their sources.

    **Return Value:** The log file as stream (arg 0) and comment (arg 1)
    """
    NAME = 'Stock Transfer Report Uploader'

    #: The expected executor class.
    EXECUTOR_CLS = StockTransferExecutor

    #: The name of the log file in the ticket.
    LOG_FILE_NAME = 'stock_transfer_%s.csv'
    #: The description of the log file description.
    LOF_FILE_DESCRIPTION = 'Log file for transfer of %s from stock to ' \
                           'preparation plates.'

    #: The ticket comment for the update.
    BASE_COMMENT = 'A stock transfer has been executed by %s ' \
                   '(see file: attachment:%s).\n\n' \
                   'Type: %s\n\n' \
                   'Involved ISOs (preparation plates): %s.\n'

    #: Shall existing replacements with the same name be overwritten?
    REPLACE_EXISTING_ATTACHMENTS = False

    #: Marks ISO job transfers (384-well cases).
    TYPE_CONTROL = 'controls'
    #: Marks ISO transfers for samples (384-well screening scenarios only).
    TYPE_SAMPLES = 'samples'
    #: Marks ISO transfers for samples and controls (96-well cases).
    TYPE_BOTH = 'controls and samples'

    def __init__(self, executor, logging_level=logging.WARNING,
                 add_default_handlers=False):
        """
        Constructor:

        :param executor: The executor tool (after run has been completed).
        :type executor: an tool implementing the methods
            :func:`get_executed_stock_worklists` and `:func:`get_working_layout`


        :param logging_level: the desired minimum log level
        :type log_level: :class:`int` (or logging_level as
                         imported from :mod:`logging`)
        :default logging_level: logging.WARNING

        :param add_default_handlers: If *True* the log will automatically add
            the default handler upon instantiation.
        :type add_default_handlers: :class:`boolean`
        :default add_default_handlers: *False*
        """
        BaseTracTool.__init__(self, logging_level=logging_level,
                              add_default_handlers=add_default_handlers,
                              depending=False)

        #: The tool that has conducted the execution.
        self.executor = executor

        #: The executed worklists that have been generated by the executor
        #: (mapped onto transfer job indices).
        self._executed_worklists = None
        #: The working_layout containing the molecule design ID data.
        self._working_layout = None

        #: The stream for the log file.
        self.__log_file_stream = None
        #: The attachment for the ticket (for the log file).
        self._log_file_attachment = None

        #: The completed ticket comment.
        self._comment = None
        #: The ticket number.
        self._ticket_number = None

        #: The run can is quit without error if there are no stock transfer
        #: executed (might be the case for the ISO series processing executor).
        self.quit_run = None

    def reset(self):
        """
        Resets all values except for the initialisation values.
        """
        BaseTracTool.reset(self)
        self._executed_worklists = None
        self._working_layout = None
        self.__log_file_stream = None
        self._ticket_number = None
        self.quit_run = False

    def send_request(self):
        """
        Generates the stream for the report and sends the request.
        """
        self.reset()
        self.add_info('Start ticket update preparations ...')

        self.__check_input()
        if not self.has_errors(): self.__fetch_executor_data()
        if not self.has_errors() and not self.quit_run:
            self.__generate_log_file_stream()
        if not self.has_errors() and not self.quit_run:
            self.__prepare_type_depending_data()
        if not self.has_errors() and not self.quit_run:
            self.__submit_request()

    def __check_input(self):
        """
        Checks the initialisation values.
        """
        self.add_debug('Check input values ...')

        if self._check_input_class('executor', self.executor,
                                   self.EXECUTOR_CLS):
            if self.executor.has_errors():
                msg = 'The executor has errors! Abort file generation.'
                self.add_error(msg)
            elif self.executor.return_value is None:
                msg = 'The executor has not run yet!'
                self.add_error(msg)

    def __fetch_executor_data(self):
        """
        Fetches the executed worklists from the generator.
        """
        self._executed_worklists = self.executor.get_executed_stock_worklists()
        self._working_layout = self.executor.get_working_layout()

        if self._executed_worklists is None or self._working_layout is None:
            msg = 'Error when trying to obtain executor data.'
            self.add_error(msg)
        elif len(self._executed_worklists) < 1:
            msg = 'There are no stock transfers. Run is quit.'
            self.add_info(msg)
            self.quit_run = True
            self.was_successful = True

    def __generate_log_file_stream(self):
        """
        Generates the log file stream.
        """
        self.add_debug('Generate log file ...')

        writer = self._get_log_file_writer()
        self.__log_file_stream = writer.get_result()

        if self.__log_file_stream is None:
            msg = 'Error when trying to generate transfer log file.'
            self.add_error(msg)

    def _get_log_file_writer(self):
        """
        By default, we use the :class:`StockTransferLogFileWriter`.
        """
        writer = StockTransferLogFileWriter(log=self.log,
                                working_layout=self._working_layout,
                                executed_worklists=self._executed_worklists)
        return writer

    def __prepare_type_depending_data(self):
        """
        Prepares the comment and the attachment and sets the ticket number.
        """
        self.add_debug('Prepare type depending data ...')

        self._set_ticket_id()
        task_type = self._get_task_type()
        plate_str = self._get_plate_str()

        username = self.executor.user.username
        entity = self.executor.entity

        file_name = self.LOG_FILE_NAME % (entity.label.replace(' ', '_'))
        self._log_file_attachment = AttachmentWrapper(
                    content=self.__log_file_stream, file_name=file_name,
                    description=self.LOF_FILE_DESCRIPTION % (entity.label))

        username = self.executor.user.username
        self._comment = self.BASE_COMMENT % (username, file_name,
                                             task_type, plate_str)

    def _set_ticket_id(self):
        """
        By default, the ticket ID is part of the experiment metadata.
        """
        iso_request = self.executor.entity.iso_request
        self._ticket_number = iso_request.experiment_metadata.ticket_number

    def _get_task_type(self):
        """
        By default, the task type depends on the entity class and the
        experiment type.
        """
        entity = self.executor.entity
        iso_request = entity.iso_request

        if self.executor.ENTITY_CLS == IsoJob:
            return self.TYPE_CONTROL
        else: # entity is ISO
            experiment_type_id = iso_request.experiment_metadata_type.id
            if entity.rack_layout.shape.name == RACK_SHAPE_NAMES.SHAPE_96:
                if experiment_type_id == EXPERIMENT_SCENARIOS.MANUAL:
                    return self.TYPE_CONTROL
                else:
                    return self.TYPE_BOTH
            elif experiment_type_id == EXPERIMENT_SCENARIOS.SCREENING:
                return self.TYPE_SAMPLES
            else:
                return self.TYPE_CONTROL

    def _get_plate_str(self):
        """
        There is 1 plae for ISOs and several plates for ISO jobs.
        """
        entity = self.executor.entity

        if self.executor.ENTITY_CLS == IsoJob:
            return self.__get_iso_job_plate_info(entity)

        else: # entity is ISO
            return '%s (%s)' % (entity.label, entity.preparation_plate)

    def __get_iso_job_plate_info(self, iso_job):
        """
        Returns a formatted info string for the comment in ISO job cases.
        """
        job_data = []
        for iso in iso_job.isos:
            iso_str = '%s (%s)' % (iso_job.label, iso.preparation_plate)
            job_data.append(iso_str)

        job_data.sort()
        return ', '.join(job_data)

    def __submit_request(self):
        """
        Submits the attachment and sends a comment.
        """
        self.add_info('Preparations completed. Update ticket ...')

        try:
            update_wrapper = create_wrapper_for_ticket_update(
                                                ticket_id=self._ticket_number)
            self.tractor_api.update_ticket(ticket_wrapper=update_wrapper,
                                           comment=self._comment,
                                           notify=self.NOTIFY)
        except ProtocolError, err:
            self.add_error(err.errmsg)
        except Fault, fault:
            msg = 'Fault %s: %s' % (fault.faultCode, fault.faultString)
            self.add_error(msg)

        try:
            self.tractor_api.add_attachment(
                        ticket_id=self._ticket_number,
                        attachment=self._log_file_attachment,
                        replace_existing=self.REPLACE_EXISTING_ATTACHMENTS)
        except ProtocolError, err:
            self.add_error(err.errmsg)
        except Fault, fault:
            msg = 'Fault %s: %s' % (fault.faultCode, fault.faultString)
            self.add_error(msg)

        if not self.has_errors():
            self.__log_file_stream.seek(0)
            self.return_value = (self.__log_file_stream, self._comment)
            self.add_info('The ticket has been updated successfully.')
            self.was_successful = True


class StockTransferLogFileWriter(CsvWriter):
    """
    Creates a log file after each stock transfer. The log file contains
    molecule designs, stock tube barcodes and volumes and the barcode and
    position in the target rack.

    **Return Value:** file stream (CSV format)
    """
    NAME = 'Stock Transfer Log File Writer'

    #: The index for the molecule design pool ID column.
    MOLECULE_DESIGN_POOL_INDEX = 0
    #: The header for the molecule design pool ID column.
    MOLECULE_DESIGN_POOL_HEADER = 'Molecule Design Pool ID'

    #: The index for the tube barcode column.
    TUBE_BARCODE_INDEX = 1
    #: The header for the tube barcode column.
    TUBE_BARCODE_HEADER = 'Stock Tube Barcode'

    #: The index for the volume column.
    VOLUME_INDEX = 2
    #: The header for the volume column.
    VOLUME_HEADER = 'Volume (ul)'

    #: The index for the target rack barcode column.
    TARGET_RACK_BARCODE_INDEX = 3
    #: The header for the target rack barcode column.
    TARGET_RACK_BARCODE_HEADER = 'Target Rack Barcode'

    #: The index for the target position column.
    TARGET_POSITION_INDEX = 4
    #: The header for the target position column.
    TARGET_POSITION_HEADER = 'Target Position'

    #: Which position of a transfer leads to the molecule design pool ID?
    _MDP_POSITION_LOOKUP = {PrepIsoLayout : 'target_position',
                            IsoControlRackLayout : 'source_position'}


    def __init__(self, working_layout, executed_worklists, log):
        """
        Constructor:

        :param working_layout: The working_layout containing the molecule
            design pool data.
        :type working_layout: :class:`PrepIsoLayout` or
            :class:`IsoControlRackLayout`

        :param executed_worklists: The executed worklists that have been
            generated by the executor (mapped onto transfer job indices).
        :type executed_worklists: :class:`dict`

        :param log: The log to write into.
        :type log: :class:`thelma.ThelmaLog`
        """
        CsvWriter.__init__(self, log=log)

        #: The executed worklists that have been generated by the executor
        #: (mapped onto transfer job indices).
        self.executed_worklists = executed_worklists
        #: The working layout containing the molecule design pool data.
        self.working_layout = working_layout

        #: Stores the values for the molecule design pool ID column.
        self.__pool_values = None
        #: Stores the values for the tube barcode column.
        self.__tube_barcode_values = None
        #: Stores the values for the volume column.
        self.__volume_values = None
        #: Stores the values for the target rack barcode column.
        self.__trg_rack_barcode_values = None
        #: Stores the values for the target position column.
        self.__trg_position_values = None

    def reset(self):
        """
        Resets all values except for the initialisation values.
        """
        CsvWriter.reset(self)
        self.__pool_values = []
        self.__tube_barcode_values = []
        self.__volume_values = []
        self.__trg_rack_barcode_values = []
        self.__trg_position_values = []

    def _init_column_map_list(self):
        """
        Creates the :attr:`_column_map_list`
        """
        self.add_info('Start log file generation ...')

        self.__check_input()
        if not self.has_errors(): self.__store_column_values()
        if not self.has_errors(): self.__generate_column_maps()

    def __check_input(self):
        """
        Checks the initialisation values.
        """
        self.add_debug('Check input values ...')

        if self._check_input_class('executed worklists map',
                                   self.executed_worklists, dict):
            for i, ew in self.executed_worklists.iteritems():
                if not self._check_input_class('worklist index', i, int): break
                if not self._check_input_class('executed worklist', ew,
                                               ExecutedWorklist): break

        self._check_input_class('working layout', self.working_layout,
                                WorkingLayout)

    def __store_column_values(self):
        """
        Store the values for the columns.
        """
        self.add_debug('Store values ...')

        target_rack_map = dict()
        for ew in self.executed_worklists.values():
            for et in ew.executed_transfers:
                target_rack_barcode = et.target_container.location.rack.barcode
                if not target_rack_map.has_key(target_rack_barcode):
                    target_rack_map[target_rack_barcode] = []
                target_rack_map[target_rack_barcode].append(et)

        barcodes = sorted(target_rack_map.keys())
        well_containers = set()

        for target_rack_barcode in barcodes:

            executed_transfers = target_rack_map[target_rack_barcode]
            pool_map = self.__get_sorted_executed_transfers(executed_transfers)
            if self.has_errors(): break

            pool_ids = sorted(pool_map.keys())
            for pool_id in pool_ids:
                ets = pool_map[pool_id]
                for et in ets:
                    self.__pool_values.append(get_trimmed_string(pool_id))

                    source_container = et.source_container
                    if not isinstance(source_container, Tube):
                        pos_label = et.planned_transfer.source_position.label
                        well_containers.add(pos_label)
                        continue

                    self.__tube_barcode_values.append(source_container.barcode)
                    volume = et.planned_transfer.volume \
                                                    * VOLUME_CONVERSION_FACTOR
                    self.__volume_values.append(get_trimmed_string(volume))
                    self.__trg_rack_barcode_values.append(target_rack_barcode)
                    self.__trg_position_values.append(
                                    et.planned_transfer.target_position.label)

        if len(well_containers) > 0:
            well_container_list = list(well_containers)
            well_container_list.sort()
            msg = 'Some source containers in the worklists are wells: %s!' \
                   % (well_container_list)
            self.add_error(msg)

    def __get_sorted_executed_transfers(self, executed_transfers):
        """
        Sorts the executed transfer of a worklist by molecule design pool ID.
        """
        pool_map = dict()
        no_pools = set()
        pool_position_name = self.__get_md_pool_position_name()
        if pool_position_name is None: return None

        for et in executed_transfers:
            rack_pos = getattr(et.planned_transfer, pool_position_name)
            wp = self.working_layout.get_working_position(rack_pos)

            if wp is None:
                no_pools.add(rack_pos.label)
                continue

            pool_id = wp.molecule_design_pool_id
            if pool_id is None:
                no_pools.add(rack_pos.label)
                continue

            if not pool_map.has_key(pool_id): pool_map[pool_id] = []
            pool_map[pool_id].append(et)

        if len(no_pools) > 0:
            no_pools_list = list(no_pools)
            no_pools_list.sort()
            msg = 'Could not find molecule design pools for the following ' \
                  'target positions: %s.' % (no_pools_list)
            self.add_error(msg)

        return pool_map

    def __get_md_pool_position_name(self):
        """
        Derives the working position from an executed transfer.
        """
        layout_type = type(self.working_layout)
        if not self._MDP_POSITION_LOOKUP.has_key(layout_type):
            msg = 'Unsupported layout type: %s.' % (layout_type.__name__)
            self.add_error(msg)
            return None
        else:
            return self._MDP_POSITION_LOOKUP[layout_type]

    def __generate_column_maps(self):
        """
        Initialises the CsvColumnParameters object for the
        :attr:`_column_map_list`.
        """
        pool_column = CsvColumnParameters(self.MOLECULE_DESIGN_POOL_INDEX,
                    self.MOLECULE_DESIGN_POOL_HEADER, self.__pool_values)
        tube_column = CsvColumnParameters(self.TUBE_BARCODE_INDEX,
                    self.TUBE_BARCODE_HEADER, self.__tube_barcode_values)
        volume_column = CsvColumnParameters(self.VOLUME_INDEX,
                    self.VOLUME_HEADER, self.__volume_values)
        rack_barcode_column = CsvColumnParameters(
                    self.TARGET_RACK_BARCODE_INDEX,
                    self.TARGET_RACK_BARCODE_HEADER,
                    self.__trg_rack_barcode_values)
        rack_position_column = CsvColumnParameters(self.TARGET_POSITION_INDEX,
                    self.TARGET_POSITION_HEADER, self.__trg_position_values)

        self._column_map_list = [pool_column, tube_column, volume_column,
                                 rack_barcode_column, rack_position_column]


